#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Mon May  6 17:11:52 2024@author: han"""import torchfrom torch_geometric.data import Dataimport pandas as pdfrom torch_geometric.datasets import Planetoidimport torch_geometric.transforms as Timport matplotlib.pyplot as pltimport jsonimport networkx as nxdef load_dataset(args):    if args.dataset_name == 'LoRa': # load self-defined dataset        df = pd.read_csv(args.dataset_root, header=None)        x_PL = torch.tensor(df.iloc[:, 0:9].values)        y_SF_Ptx = torch.tensor(df.iloc[:, 9:].values)                mean_PL = torch.mean(x_PL).tolist()        std_PL = torch.std(x_PL).tolist()                statistics = {"mean": mean_PL,"std": std_PL}        with open(args.folder_to_save_files+'/statistics.json', "w") as json_file:            json.dump(statistics, json_file)        nor_x_PL = (x_PL - mean_PL) / std_PL        return nor_x_PL, y_SF_Ptx    else:        dataset = Planetoid(root='dataset/' + args.dataset_name, name=args.dataset_name, transform=T.NormalizeFeatures())        return dataset         def map_to_embedding(input_data, embedding_dim, embedding_layer):    """    Args:        input_data (torch.Tensor): input shape is [num_samples, num_nodes]        embedding_dim (int):     Returns:        torch.Tensor: output shape is [num_samples, num_nodes, num_edge_features]    """    num_samples, num_features = input_data.shape    # embedding_layers = nn.ModuleList([nn.Linear(1, embedding_dim) for _ in range(num_features)])    embedded_features = []    for i in range(num_features):        feature_data = input_data[:, i:i+1].float()                 embedded_feature = embedding_layer(feature_data)         embedded_feature = embedded_feature.unsqueeze(1)                embedded_features.append(embedded_feature)        embedded_data = torch.cat(embedded_features, dim=1)    return embedded_datadef process_edge_features(input_data, args):    """    Args:        input_data (torch.Tensor): input shape is [num_samples, 18]        num_edge_features1 (int): Number of categories for the first edge feature type (SF values).        num_edge_features2 (int): Number of categories for the second edge feature type (Ptx values).    Returns:        torch.Tensor: output shape is [num_samples, num_edges, num_edge_features1 + num_edge_features2]    """    num_samples = input_data.size(0)    num_features = input_data.size(1)    assert num_features == args.edge_num*2, "Error: Input data must have 2*num_edges features"        edge_features = []    for i in range(args.edge_num):        feature1_idx = i        feature2_idx = i + args.edge_num        edge_feature_pair = input_data[:, [feature1_idx, feature2_idx]]        edge_features.append(edge_feature_pair)        # one-hot encoding    encoded_edge_features = []    for edge_feature in edge_features:        feature1_values = edge_feature[:, 0]        feature2_values = edge_feature[:, 1]        # Map SF values to one-hot encoding        sf_encoded = torch.zeros(len(feature1_values), args.SF_num)        for idx, value in enumerate(feature1_values):            if value.item() in args.SF_mapping:                sf_encoded[idx, args.SF_mapping[value.item()]] = 1                # Map Ptx values to one-hot encoding        ptx_encoded = torch.zeros(len(feature2_values), args.Ptx_num)        for idx, value in enumerate(feature2_values):            if value.item() in args.Ptx_mapping:                ptx_encoded[idx, args.Ptx_mapping[value.item()]] = 1        # Combine the encoded features        combined_feature = torch.cat([sf_encoded.float(), ptx_encoded.float()], dim=1)        encoded_edge_features.append(combined_feature)        processed_data = torch.stack(encoded_edge_features, dim=1)    assert processed_data.size() == (num_samples, args.edge_num, args.SF_num + args.Ptx_num), "Output tensor shape mismatch"    return processed_data def create_graph_data(node_features, edge_index, edge_features=None):    num_samples = node_features.shape[0]    data_list = []    for i in range(num_samples):        x = node_features[i]          if edge_features is not None:            edge_attr = edge_features[i]            # graph_data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)            graph_data = Data(x=x, edge_index=edge_index, y=edge_attr) # save in node-level        else:            graph_data = Data(x=x, edge_index=edge_index) # save in node-level        data_list.append(graph_data)    return data_list            def cal_accuracy(pred_SF, pred_Ptx, label_SF, label_Ptx):    est_SF= torch.argmax(pred_SF, dim=1)    est_Ptx= torch.argmax(pred_Ptx, dim=1)    SF_err = torch.sum((est_SF != label_SF)).item()    Ptx_err = torch.sum((est_Ptx != label_Ptx)).item()    return SF_err, Ptx_err        def remove_empty_node(data_SF, data_Ptx, batch_size):    indices_to_keep = [i for i in range(len(data_SF)) if i % (data_SF.size(0) // batch_size) != 0]    data_SF = data_SF[indices_to_keep]    data_Ptx = data_Ptx[indices_to_keep]    return data_SF, data_Ptxclass TrainLogger():    def __init__(self, path, title=None):        if title == None:            self.title = ['Epoch', 'Training loss', 'Test loss', 'SF_Acc', 'Ptx_Acc']        else:            self.title = title        self.data = []        self.path = path        def update(self, log):        self.data.append(log)        df = pd.DataFrame(data=self.data, columns=self.title)        df.to_csv(self.path + '/log.csv', index=False, sep=',')            def plot(self):        #####        data = pd.read_csv(self.path + '/log.csv')        plt.figure(figsize=(6,6))        # MSE Plot        plt.plot(data['Epoch'], data['Training loss'], label='Training loss')        plt.plot(data['Epoch'], data['Test loss'], label='Validation loss')        plt.legend()        plt.xlabel('Epoch')        plt.ylabel('CE Loss')        plt.tight_layout()        plt.grid()        plt.savefig(f'{self.path}/training_loss.png')        plt.close()        def draw_graph(G):    nx_graph = nx.DiGraph()    for i in range(G.x.size(0)):        nx_graph.add_node(i)    for i in range(G.edge_index.size(1)):        u = G.edge_index[0, i].item()        v = G.edge_index[1, i].item()        nx_graph.add_edge(u, v)    pos = nx.spring_layout(nx_graph, scale=1)    nx.draw(nx_graph, pos, with_labels=True, node_size=1000, node_color="skyblue", font_size=20, font_color="black")    nx.draw_networkx_edges(nx_graph, pos, edgelist=nx_graph.edges(), arrowstyle='-|>', arrowsize=40,  width=2)    plt.show()    #%%# conbine datasets# import pandas as pd# import numpy as np# # 读取第一个 CSV 文件 (500行)# df1 = pd.read_csv('dataset/LoRa/LoRadataset_GT_test1.csv', header=None)# # 读取第二个 CSV 文件 (4500行)# df2 = pd.read_csv('dataset/LoRa/LoRadataset_GT_test2.csv', header=None)# # 拼接两个数据框# combined_df = pd.concat([df1, df2], ignore_index=True)# data_array = combined_df.to_numpy()# # 保存拼接后的数据框为新的 CSV 文件# np.savetxt('dataset/LoRa/LoRadataset_GT_test_100.csv', data_array, delimiter=',', fmt='%s')